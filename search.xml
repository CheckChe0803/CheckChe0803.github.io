<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>flink使用06-如何处理窗口内的数据</title>
      <link href="/2019/09/26/flink%E4%BD%BF%E7%94%A806-%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E7%AA%97%E5%8F%A3%E5%86%85%E7%9A%84%E6%95%B0%E6%8D%AE/"/>
      <url>/2019/09/26/flink%E4%BD%BF%E7%94%A806-%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E7%AA%97%E5%8F%A3%E5%86%85%E7%9A%84%E6%95%B0%E6%8D%AE/</url>
      
        <content type="html"><![CDATA[<p>上一节主要是大致介绍了下 flink 的窗口组成, 以及如何去划分窗口的. 那么这一篇文章主要是对剩下的内容做一下总结, 说一下如何对窗口内的数据做处理.  </p><h4 id="Window-Function"><a href="#Window-Function" class="headerlink" title="Window Function"></a>Window Function</h4><p>Window Assigner 的作用是划分窗口的, 而 Window Function 就是对窗口内的数据做处理的一个过程. Flink 提供了 4 种类型的 Window Function, 分别是 ReduceFunction / AggregateFunction / FoldFunction / ProcessWindowFunction. 另外, 这四类还根据计算原理的不同分为增量聚合函数和全量窗口函数. 增量的计算性能比较高, 主要是基于中间状态的计算结果, 窗口中只维护中间结果的状态值.</p><h4 id="1-ReduceFunction-增量"><a href="#1-ReduceFunction-增量" class="headerlink" title="1. ReduceFunction (增量)"></a><strong>1. ReduceFunction</strong> (增量)</h4><p>对输入的两个相同类型的元素按照指定的计算方式进行聚合, 通过实现 ReduceFunction 接口就可以在reduce( ) 函数内部进行聚合操作了.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 将Tuple2 按照 f1 进行 keyBy, 之后将 f0字符合并起来</span></span><br><span class="line">input.keyBy(x -&gt; x.f1)</span><br><span class="line">.timeWindow(Time.seconds(<span class="number">10</span>), Time.seconds(<span class="number">1</span>))</span><br><span class="line">    .reduce(<span class="keyword">new</span> ReduceFunction&lt;Tuple2&lt;String, Long&gt;&gt;() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> Tuple2&lt;String, Long&gt; <span class="title">reduce</span><span class="params">(Tuple2&lt;String, Long&gt; t1, Tuple2&lt;String, Long&gt; t2)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Tuple2&lt;&gt;(t1.f0 + t2.f0, t1.f1);</span><br><span class="line">        &#125;</span><br><span class="line">        &#125;);</span><br></pre></td></tr></table></figure><p>当然也可以使用匿名函数的方式,写起来会更加简洁.上述代码可以改为:</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">input.keyBy(x -&gt; x.f1).timeWindow(Time.seconds(<span class="number">10</span>), Time.seconds(<span class="number">1</span>))</span><br><span class="line">.reduce((t1,t2) -&gt; <span class="keyword">new</span> Tuple2&lt;&gt;(t1.f0 + t2.f0, t1.f1));</span><br></pre></td></tr></table></figure><h4 id="2-AggregateFunction-增量"><a href="#2-AggregateFunction-增量" class="headerlink" title="2. AggregateFunction (增量)"></a><strong>2. AggregateFunction</strong> (增量)</h4><p>AggregateFunction 相对于ReduceFunction更加灵活,但是实现起来也更复杂, AggregateFunction有 4 个需要复写的方法, 其中createAccumulator( ) 定义累加器, add( ) 定义数据的添加逻辑, getResult( ) 定义了根据 accumulator 计算结果的逻辑, merge()方法定义合并 accumulator 的逻辑.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">input.keyBy(x -&gt; x.f1)</span><br><span class="line">    .timeWindow(Time.seconds(<span class="number">10</span>), Time.seconds(<span class="number">1</span>))</span><br><span class="line">    <span class="comment">// 自定义一个AggregateFunciton, 将相同标号 f1 的数据的 f0字符串字段合并在一起</span></span><br><span class="line">    <span class="comment">// ("hello", 1L) + ("world", 1L) = ("hello world", 1L)</span></span><br><span class="line">    .aggregate(<span class="keyword">new</span> MyAggregateFunction());</span><br></pre></td></tr></table></figure><p>通过自定义的 MyAggregateFunction() 来实现 AggregateFunction 接口</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyAggregateFunction</span> <span class="keyword">implements</span> <span class="title">AggregateFunction</span>&lt;<span class="title">Tuple2</span>&lt;<span class="title">String</span>, <span class="title">Long</span>&gt;, <span class="title">String</span>, <span class="title">String</span>&gt;</span>&#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">createAccumulator</span><span class="params">()</span> </span>&#123;</span><br><span class="line">        <span class="comment">// 初始化累加器</span></span><br><span class="line">            <span class="keyword">return</span> <span class="string">""</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">add</span><span class="params">(Tuple2&lt;String, Long&gt; t, String s)</span> </span>&#123;</span><br><span class="line">            <span class="comment">// 输入数据与累加器的合并</span></span><br><span class="line">            <span class="keyword">return</span> s + <span class="string">" "</span> +t.f0;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">getResult</span><span class="params">(String s)</span> </span>&#123;</span><br><span class="line">            <span class="comment">// 得到累加器的结果</span></span><br><span class="line">            <span class="keyword">return</span> s.trim();</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> String <span class="title">merge</span><span class="params">(String s, String acc1)</span> </span>&#123;</span><br><span class="line">            <span class="comment">// 合并累加器</span></span><br><span class="line">            <span class="keyword">return</span> s + <span class="string">" "</span> + acc1;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><h4 id="3-FoldFunction-增量"><a href="#3-FoldFunction-增量" class="headerlink" title="3. FoldFunction (增量)"></a><strong>3. FoldFunction</strong> (增量)</h4><p>FoldFunction定义了如何将窗口中的输入元素与外部的元素合并的逻辑</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">input.keyBy(x -&gt; x.f1)</span><br><span class="line">.timeWindow(Time.seconds(<span class="number">10</span>), Time.seconds(<span class="number">1</span>)).fold(<span class="string">"flink"</span>, (acc, t) -&gt;t.f0 + acc);</span><br></pre></td></tr></table></figure><p>FoldFunction在新版本已经被标记@Deprecated了, 建议使用AggregateFunction代替</p><h4 id="4-ProcessWindowFunction-全量"><a href="#4-ProcessWindowFunction-全量" class="headerlink" title="4. ProcessWindowFunction (全量)"></a><strong>4. ProcessWindowFunction</strong> (全量)</h4><p>ProcessWindowFunction 相较于其他的 Window Function, 可以实现一些更复杂的计算, 比如基于整个窗口做某些指标计算 或者需要操作窗口中的状态数据和窗口元数据. Flink 提供了 ProcessWindowFunction 这个抽象类, 继承此类就可以实现ProcessWindowFunction, 其中, 必须要实现 process( ) 方法, 这是处理窗口数据的主要方法.还在一下跟窗口数据相关的方法可以有选择的实现.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">MyProcessWindowFunction</span> <span class="keyword">extends</span> <span class="title">ProcessWindowFunction</span>&lt;<span class="title">Tuple3</span>&lt;<span class="title">String</span>, <span class="title">Long</span>, <span class="title">Long</span>&gt;, <span class="title">String</span>, <span class="title">Long</span>, <span class="title">TimeWindow</span>&gt; </span>&#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(Long s, Context context, Iterable&lt;Tuple3&lt;String, Long, Long&gt;&gt; elements, Collector&lt;String&gt; out)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"><span class="comment">// 统计每个窗口内的所有数据的 f0字段加起来共有多少个单词</span></span><br><span class="line">    <span class="comment">// 也就做单个窗口的 wordcount</span></span><br><span class="line">Long count = <span class="number">0L</span>;</span><br><span class="line"><span class="keyword">for</span> (Tuple3&lt;String, Long, Long&gt; element : elements) &#123;</span><br><span class="line">count += element.f0.split(<span class="string">" "</span>).length;</span><br><span class="line">&#125;</span><br><span class="line">out.collect(<span class="string">"window: "</span> + context.window() + <span class="string">" word count: "</span> + count);</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h4 id="5-增量与全量共同使用"><a href="#5-增量与全量共同使用" class="headerlink" title="5. 增量与全量共同使用"></a>5. 增量与全量共同使用</h4><p>增量聚合函数虽然性能好, 但是灵活性不如全量函数, 例如对窗口状态数据的操作以及对窗口中的元数据信息的获取. 但是如果用 ProcessWindowFunction 去完成一些基础的增量计算相对比较浪费资源, 因此可以两者结合的方式来实现.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">input.keyBy(x -&gt; x.f1)</span><br><span class="line">.timeWindow(Time.seconds(<span class="number">10</span>), Time.seconds(<span class="number">1</span>))</span><br><span class="line"><span class="comment">// 第一个Function为 ReduceFunction, 取窗口的最小值</span></span><br><span class="line">.reduce((r1, r2) -&gt; &#123;</span><br><span class="line"><span class="keyword">return</span> r1.f0 &lt; r2.f0 ? r1 : r2;</span><br><span class="line"><span class="comment">// 第二个Function为 ProcessWindowFunction, 获取窗口的时间信息</span></span><br><span class="line">&#125;, <span class="keyword">new</span> ProcessWindowFunction&lt;Tuple2&lt;Long, Long&gt;, String, Long, TimeWindow&gt;() &#123;</span><br><span class="line"><span class="meta">@Override</span></span><br><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">process</span><span class="params">(Long aLong, Context context, Iterable&lt;Tuple2&lt;Long, Long&gt;&gt; elements, Collector&lt;String&gt; out)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">out.collect(<span class="string">"window: "</span> + context.window()); </span><br><span class="line">&#125;</span><br><span class="line">&#125;).print();</span><br></pre></td></tr></table></figure><h3 id="Flink-窗口中的其他组件"><a href="#Flink-窗口中的其他组件" class="headerlink" title="Flink 窗口中的其他组件"></a>Flink 窗口中的其他组件</h3><p>除了 Window Assigner 和 Window Function外,Flink的窗口中还有 Triger窗口触发器, 其负责判断何时将窗口中的数据取出做计算, flink已经默认为各种类型的窗口实现了 triger. 用户也可以自己手动指定. Evictors 是数据剔除器, 目的是把窗口中的数据按照需求做一定的剔除. Flink也有 API 针对延迟数据做处理, 延迟的数据可以丢弃也可以通过sideOutputLateDate( ) 方法处理.</p><h4 id="1-Triger-窗口触发器"><a href="#1-Triger-窗口触发器" class="headerlink" title="1. Triger 窗口触发器"></a>1. Triger 窗口触发器</h4><p><strong>EventTimeTrigger</strong>: 通过对比 watermark 和窗口 EndTime 确定是否触发窗口</p><p><strong>ProcessTimeTrigger</strong>: 通过对比 ProcessTime 和窗口 EndTime 确定是否触发窗口</p><p><strong>ContinuousEventTimeTrigger</strong>: 根据间隔时间周期性触发窗口</p><p><strong>ContinuousEventTimeTrigger</strong>: 同上, 区别是使用ProcessTime</p><p><strong>CountTrigger</strong>: 根据接入数量是否超过阈值</p><p><strong>DeltaTrigger</strong>: 根据计算出来的 Delta 指标是否超过指定的 Threshold</p><p><strong>PurgingTrigger</strong>: 可以将任意触发器作为参数转换为Purge类型触发器</p><h4 id="2-Evictors触发器"><a href="#2-Evictors触发器" class="headerlink" title="2. Evictors触发器"></a>2. Evictors触发器</h4><p>CountEvictor: 保持固定数量的数据, 超过的剔除</p><p>DeltaEvictor: 通过定义 delta 和 threshold , 计算两个数据之间的 delta 值, 超过则剔除</p><p>TimeEvictor: 指定时间间隔, 将当前窗口中的最新元素的时间减去Interval, 然后将小于该结果的数据全部剔除</p>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> window </tag>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>flink使用05-窗口简介和简单的使用</title>
      <link href="/2019/09/25/flink%E4%BD%BF%E7%94%A805-%E7%AA%97%E5%8F%A3%E7%AE%80%E4%BB%8B%E5%92%8C%E7%AE%80%E5%8D%95%E7%9A%84%E4%BD%BF%E7%94%A8/"/>
      <url>/2019/09/25/flink%E4%BD%BF%E7%94%A805-%E7%AA%97%E5%8F%A3%E7%AE%80%E4%BB%8B%E5%92%8C%E7%AE%80%E5%8D%95%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h3 id="1-窗口组成简介"><a href="#1-窗口组成简介" class="headerlink" title="1. 窗口组成简介"></a>1. 窗口组成简介</h3><p>窗口是流式计算中非常重要的一个概念, 很多常见的功能都是通过各种窗口实现的, 比如每5分钟统计一下刚去1小时的热度. Flink DataStream API 将窗口独立成 Operator. 每个窗口算子包含了以下几个部分:</p><h4 id="Windows-Assigner"><a href="#Windows-Assigner" class="headerlink" title="Windows Assigner"></a>Windows Assigner</h4><p>指定窗口的类型, 定义如何将数据流分配到一个或者多个窗口</p><h4 id="Windows-Trigger"><a href="#Windows-Trigger" class="headerlink" title="Windows Trigger"></a>Windows Trigger</h4><p>指定窗口触发的时机, 定义窗口满足什么样的条件触发计算</p><h4 id="Evictor"><a href="#Evictor" class="headerlink" title="Evictor"></a>Evictor</h4><p>用户数据剔除</p><h4 id="Lateness"><a href="#Lateness" class="headerlink" title="Lateness"></a>Lateness</h4><p>标记是否处理迟到的数据, 当迟到数据到达窗口中是否触发计算</p><h4 id="Output-Tag"><a href="#Output-Tag" class="headerlink" title="Output Tag"></a>Output Tag</h4><p>标记输出标签, 然后再通过 getSideOutput 将窗口中的数据根据标签输出</p><h4 id="Windows-Function"><a href="#Windows-Function" class="headerlink" title="Windows Function"></a>Windows Function</h4><p>定义窗口上的数据处理的逻辑, 例如对数据进行sum</p><hr><h3 id="2-Window-Assigner"><a href="#2-Window-Assigner" class="headerlink" title="2. Window Assigner"></a>2. Window Assigner</h3><p>首先最需要了解的就是 windows Assigner了, 我们想要一个什么样的窗口划分, 主要就是通过他来实现的. </p><p>根据 flink 上游的数据集是否为 KeyedStream 类型 来做分别的处理. 如果使用了keyBy( ) 则对应使用window( ) 来处理, 否则可以使用 windowAll( )来使用</p><p>Flink 可以支持两种类型的窗口, 分别是基于时间的窗口和基于数量的窗口.基于时间的意思就是按照时间去划分窗口,同理,基于数量的也是根据窗口中的数量来做切分的. 对应的分别就是 timeWindow() 和 countWindow() 来使用, 下面的示例主要使用 timeWindow() 来演示.</p><p>对于不同的 Window Assigner, 还可以把窗口划分为4大类, 分别是 滚动窗口(Tumbling Windows) / 滑动窗口(Sliding Window) / 会话窗口(Session Window) 和 全局窗口(Global Window).</p><h4 id="滚动窗口"><a href="#滚动窗口" class="headerlink" title="滚动窗口"></a>滚动窗口</h4><p>DataStream API 提供基于 EventTime 和 ProcessingTime 的两种类型的 Tumbling window.对应的 Assigner 分别是 TumblingEventTimeWindow 和 ProcessingEventTimeWindow . 举例如下,完整代码见Github.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 使用ProcessTime的滚动时间窗口, 长度为10s</span></span><br><span class="line">stream.keyBy(x -&gt; x.f1)</span><br><span class="line">    .window(TumblingProcessingTimeWindows.of(Time.seconds(<span class="number">10</span>))).process(...)</span><br><span class="line"><span class="comment">// 使用ProcessTime的滚动时间窗口, 长度为10s</span></span><br><span class="line">stream.keyBy(x -&gt;x.f1).window(TumblingEventTimeWindows.of(Time.seconds(<span class="number">10</span>))).process(...)</span><br></pre></td></tr></table></figure><p>使用 window(TumblingProcessingTimeWindows.of(Time.seconds(10))) 的方法有点啰嗦, Flink 还提供了timeWindow( ) 的 API 来简化这一行代码. </p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 直接使用 timeWindow API 便可实现滚动窗口的操作, 参数依旧是窗口的长度</span></span><br><span class="line"><span class="comment">// 窗口类型的时间由 time characteristic 确定, 如果指定为 event time,那么窗口也会自动用这个时间</span></span><br><span class="line">input.keyBy(x -&gt; x.f1).timeWindow(Time.seconds(<span class="number">10</span>));</span><br></pre></td></tr></table></figure><h4 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h4><p>滑动窗口顾名思义就是一个在不断往后滑动的窗口, 比如说 每5分钟 统计一个 最近一小时的时间, 那么就需要用滑动窗口来做处理. 滑动窗口主要是依靠 window size 和 slide time 来确定. 与滚动窗口类似的, flink 也提供了对应不同时间的 Assigner API(SlidingEventTimeWindow / SlidingEventTimeWindow), 语法基本类似, 只是由原本的一个参数(窗口长度) 变为了两个参数(窗口长度和滑动时间), 同样的, 为了简化代码, 依然可以使用timeWindow() 来简化.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 两个参数分别是 窗口长度 和 滑动时间, 窗口时间类型依旧通过time characteristic 确定</span></span><br><span class="line">input.keyBy(x -&gt; x.f1).timeWindow(Time.seconds(<span class="number">10</span>), Time.seconds(<span class="number">1</span>))</span><br></pre></td></tr></table></figure><h4 id="会话窗口"><a href="#会话窗口" class="headerlink" title="会话窗口"></a>会话窗口</h4><p>会话窗口主要是将某段时间内活跃度较高的数据聚合成一个窗口计算. 触发条件是 Session Gap. 在规定的时间内没有数据接入则认为这个窗口结束,然后触发窗口计算. Session Gap 除了固定间隔的方式, 也可以动态抽取.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建 Session Window, 间隔为 3s</span></span><br><span class="line">        DataStream&lt;Tuple3&lt;String, Long, Integer&gt;&gt; aggregated = source</span><br><span class="line">                .keyBy(<span class="number">0</span>)</span><br><span class="line">                .window(EventTimeSessionWindows.withGap(Time.seconds(<span class="number">3L</span>)))</span><br><span class="line">                .sum(<span class="number">2</span>);</span><br></pre></td></tr></table></figure><h4 id="全局窗口"><a href="#全局窗口" class="headerlink" title="全局窗口"></a>全局窗口</h4><p>全局窗口将所有key的数据分配到单个窗口中计算结果.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 创建 GlobalWindow</span></span><br><span class="line">        input.keyBy(<span class="number">1</span>)</span><br><span class="line">                .window(GlobalWindows.create())</span><br><span class="line">                .sum(<span class="number">1</span>);</span><br></pre></td></tr></table></figure><p><strong>上面就是构建不同的窗口的方法了, 下文会介绍在有了窗口之后怎样对窗口中的数据做处理</strong></p>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> window </tag>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>flink使用04-几种时间概念和watermark</title>
      <link href="/2019/09/24/flink%E4%BD%BF%E7%94%A804-%E5%87%A0%E7%A7%8D%E6%97%B6%E9%97%B4%E6%A6%82%E5%BF%B5%E5%92%8Cwatermark/"/>
      <url>/2019/09/24/flink%E4%BD%BF%E7%94%A804-%E5%87%A0%E7%A7%8D%E6%97%B6%E9%97%B4%E6%A6%82%E5%BF%B5%E5%92%8Cwatermark/</url>
      
        <content type="html"><![CDATA[<h3 id="时间概念"><a href="#时间概念" class="headerlink" title="时间概念"></a>时间概念</h3><p>在做实时计算的时候, 首先就需要搞清楚一个问题, 这个实时到底是怎么样的一个时间概念. 在 Flink 中, 总共有3种时间概念, 分别是 <strong>事件时间</strong> ( Event time ) / <strong>处理时间</strong> ( Processing time ) / <strong>接入时间</strong> ( Ingestion time).</p><p><img src="/2019/09/24/flink使用04-几种时间概念和watermark/%E6%97%B6%E9%97%B4%E7%9A%84%E6%A6%82%E5%BF%B5.png" alt></p><p><strong>事件时间</strong> ( Event time )就是真实的用户发生操作的时候所产生的时间, 对应到 flink 中, 需要用户 <strong>显示</strong> 的告诉 flink 到底每个输入中的哪一个字段代表这个事件时间。</p><p><strong>接入时间</strong> ( Ingestion time) 和<strong>处理时间</strong> ( Processing time )是不需要用户去指定的, flink自己会去处理这个时间. 接入时间的代表的是一个事件通过 source Operator 的时间, 相比于 event time, ingestion time 不能处理乱序事件, 因此也就不用生成对应的watermark. 处理时间是指事件在操作算子计算过程中获取到的所在主机的时间. processing time 适合用于时间计算精度要求不是特别高的计算场景, 例如统计某些延时非常高的日志数据.</p><hr><h3 id="水位线机制-watermark"><a href="#水位线机制-watermark" class="headerlink" title="水位线机制 watermark"></a>水位线机制 watermark</h3><h4 id="1-解释-watermark"><a href="#1-解释-watermark" class="headerlink" title="1, 解释 watermark"></a>1, 解释 watermark</h4><p>watermark 这个概念在 flink 中是与 event time 这个时间概念相互依存的, 其目的是为了解决数据乱序到达和系统延迟的问题. flink会把读取进系统的最新事件时间减去固定的时间间隔作为 watermark. 还是用一张图来解释watermark 的作用.</p><p>当事件进入 flink 中的时候, 根据提取的 event time 产生 watermark 时间戳, 记为 X, 进入 flink 中的 event time 记为 Y. 当窗口的 end time &lt; X 的时候, 则触发窗口计算结果并输出. 只要 X &lt; end time, 那么 事件就可以 一直进入到当前窗口中, 这样的话即便发生乱序, 也可以在窗口中调整. 调整的方法就是按照 Y. </p><p><img src="/2019/09/24/flink使用04-几种时间概念和watermark/watermark.gif" alt></p><h4 id="2-使用-watermark"><a href="#2-使用-watermark" class="headerlink" title="2, 使用 watermark"></a>2, 使用 watermark</h4><p> a. 在 Source Function 中 直接指定 Timestamps 和 Watermark</p><p>​    用户需要复写 SourceFunction 接口中 run( ) 方法实现数据逻辑, 同时调用 SourceContext 的 collectWithTimestamp( ) 方法生成 event time 时间戳, 调用 emitWatermark( ) 方法生成 watermark.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">DataStream&lt;String&gt; text = env.addSource(<span class="keyword">new</span> SourceFunction&lt;String&gt;() &#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">run</span><span class="params">(SourceContext&lt;String&gt; ctx)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">                <span class="keyword">for</span> (String s : elementInput) &#123;</span><br><span class="line">                    <span class="comment">// 切割每一条数据</span></span><br><span class="line">                    String[] inp = s.split(<span class="string">","</span>);</span><br><span class="line">                    Long timestamp = <span class="keyword">new</span> Long(inp[<span class="number">1</span>]);</span><br><span class="line">                    <span class="comment">// 生成 event time 时间戳</span></span><br><span class="line">                    ctx.collectWithTimestamp(s, timestamp);</span><br><span class="line">                    <span class="comment">// 调用 emitWatermark() 方法生成 watermark, 最大延迟设定为 2</span></span><br><span class="line">                    ctx.emitWatermark(<span class="keyword">new</span> Watermark(timestamp - <span class="number">2</span>));</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="comment">// 设定默认 watermark</span></span><br><span class="line">                ctx.emitWatermark(<span class="keyword">new</span> Watermark(Long.MAX_VALUE));</span><br><span class="line">            &#125;</span><br><span class="line"></span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">cancel</span><span class="params">()</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;);</span><br></pre></td></tr></table></figure><p>b. 通过 Flink 自带的 Timestamp Assigner 指定 Timestamp 和 生成 watermark </p><p>在使用了 flink 定义的外部数据源( 如 kafka) 之后, 就不能通过自定义 sourcefunction 的方式来生成 watermark 和 event time 了, 这个时候可以使用 Timestamp Assigner,  其需要在第一个时间相关的 Operator前使用. Flink 有自己定义好的 Timestamp Assigner 可以直接使用 (包括直接指定的方式和固定时间延迟的方式 ).Flink 将 watermark 分为 Periodic Watermarks (根据设定的时间间隔周期性的生成) 和 Punctuated Watermarks (根据接入数量生成), 用户也可以继承对应的类实现这两种 watermark.</p><p>b.1 使用 Ascending Timestamp Assigner 指定 Timestamps 和 Watermark</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 首先需要指定系统时间概念为 event time</span></span><br><span class="line">env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime);</span><br><span class="line"><span class="comment">// 使用 Ascending 分配 时间信息和 watermark</span></span><br><span class="line">   DataStream&lt;Tuple2&lt;String, Long&gt;&gt; text = env.fromCollection(collectionInput);</span><br><span class="line">   text.assignTimestampsAndWatermarks(<span class="keyword">new</span> AscendingTimestampExtractor&lt;Tuple2&lt;String, Long&gt;&gt;() &#123;</span><br><span class="line">   <span class="meta">@Override</span></span><br><span class="line">   <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">extractAscendingTimestamp</span><span class="params">(Tuple2&lt;String, Long&gt; element)</span> </span>&#123;</span><br><span class="line">   <span class="keyword">return</span> element.f1;</span><br><span class="line">   &#125;</span><br><span class="line">   &#125;);</span><br></pre></td></tr></table></figure><p>b.2 使用固定时延间隔的 Timestamp Assigner 指定</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 使用 Ascending 分配 时间信息和 watermark 设定10s 代表最长的时延</span></span><br><span class="line">    DataStream&lt;Tuple2&lt;String, Long&gt;&gt; text = env.fromCollection(collectionInput);</span><br><span class="line">    text.assignTimestampsAndWatermarks(<span class="keyword">new</span> BoundedOutOfOrdernessTimestampExtractor&lt;Tuple2&lt;String, Long&gt;&gt;(Time.seconds(<span class="number">10</span>)) &#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">long</span> <span class="title">extractTimestamp</span><span class="params">(Tuple2&lt;String, Long&gt; element)</span> </span>&#123;</span><br><span class="line">            <span class="keyword">return</span> element.f1;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br></pre></td></tr></table></figure><p>c. 自定义 Timestamp Assigner 和 Watermark Generator</p><p>用户可以自定义实现 AssignerWithPeriodicWatermarks 和 AssignerWithPunctuatedWatermarks 两个接口来分别生成对应的两种 watermark. 这一块用的比较少, 以后有机会再细写.</p>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
            <tag> time </tag>
            
            <tag> watermark </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>flink使用03-数据输入的几种不同方法</title>
      <link href="/2019/09/04/flink%E4%BD%BF%E7%94%A803-%E6%95%B0%E6%8D%AE%E8%BE%93%E5%85%A5%E7%9A%84%E5%87%A0%E7%A7%8D%E4%B8%8D%E5%90%8C%E6%96%B9%E6%B3%95/"/>
      <url>/2019/09/04/flink%E4%BD%BF%E7%94%A803-%E6%95%B0%E6%8D%AE%E8%BE%93%E5%85%A5%E7%9A%84%E5%87%A0%E7%A7%8D%E4%B8%8D%E5%90%8C%E6%96%B9%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h3 id="flink的数据输入源主要分为两大类"><a href="#flink的数据输入源主要分为两大类" class="headerlink" title="flink的数据输入源主要分为两大类:"></a>flink的数据输入源主要分为两大类:</h3><h4 id="1-内置数据源"><a href="#1-内置数据源" class="headerlink" title="1. 内置数据源"></a>1. 内置数据源</h4><ul><li><p>集合数据源</p><p>可以将数组或者集合作为 flink 的数据源,分别有不同的方法可以使用, 这种方式比较适合本地调试使用</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">// 添加数组作为数据输入源</span><br><span class="line">String[] elementInput = new String[]&#123;&quot;hello Flink&quot;, &quot;Second Line&quot;&#125;;</span><br><span class="line">DataStream&lt;String&gt; text = env.fromElements(elementInput);</span><br><span class="line"></span><br><span class="line">// 添加List集合作为数据输入源</span><br><span class="line">List&lt;String&gt; collectionInput = new ArrayList&lt;&gt;();</span><br><span class="line">collectionInput.add(&quot;hello Flink&quot;);</span><br><span class="line">DataStream&lt;String&gt; text2 = env.fromCollection(collectionInput);</span><br></pre></td></tr></table></figure></li><li><p>Socket数据源</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">// 添加Socket作为数据输入源</span><br><span class="line">// 4个参数 -&gt; (hostname:Ip地址, port:端口, delimiter:分隔符, maxRetry:最大重试次数)</span><br><span class="line">DataStream&lt;String&gt; text3 = env.socketTextStream(&quot;localhost&quot;, 9999, &quot;\n&quot;, 4);</span><br></pre></td></tr></table></figure></li><li><p>文件数据源</p><p>可以使用 readTextFile 方法直接读取文本文件, 这种方式可以用来监控一下 log 日志文件, 也可以使用 readFile 方法通过指定 InputFormat 来读取特定数据类型的文件, InputFormat可以是内置类,如 CsvInputFormat 或者用户自定义 InputFormat 接口类.</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">// 添加文件源</span><br><span class="line">// 直接读取文本文件</span><br><span class="line">DataStream&lt;String&gt; text4 = env.readTextFile(&quot;/opt/history.log&quot;);</span><br><span class="line"></span><br><span class="line">// 指定 CsvInputFormat, 监控csv文件(两种模式), 时间间隔是10ms</span><br><span class="line">        DataStream&lt;String&gt; text5 = env.readFile(new CsvInputFormat&lt;String&gt;(new Path(&quot;/opt/history.csv&quot;)) &#123;</span><br><span class="line">            @Override</span><br><span class="line">            protected String fillRecord(String s, Object[] objects) &#123;</span><br><span class="line">                return null;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;,&quot;/opt/history.csv&quot;, FileProcessingMode.PROCESS_CONTINUOUSLY,10);</span><br></pre></td></tr></table></figure><p>在 readFile() 方法中有一项参数为 WatchType, 共有两种模式 (PROCESS_CONTINUOUSLY / PROCESS_ONCE). 在 PROCESS_CONTINUOUSLY  模式下, 检测到文件变动就会将文件全部内容加载在 flink, 在 PROCESS_ONCE 模式下, 只会将文件变动的那部分加载到 flink.  </p></li></ul><h4 id="2-外部数据源"><a href="#2-外部数据源" class="headerlink" title="2. 外部数据源"></a>2. 外部数据源</h4><p>外部数据源是重头戏, 一般来说项目中均是使用外部数据源作为数据的源头, flink 通过实现 SourceFunction 定义了非常丰富的第三方数据连接器</p><ul><li><p>数据源连接器</p><p>对于第三方数据源, flink的支持分为三种,有只读型(Twitter Streaming API / Netty ), 只写型( Cassandra / Elasticsearch / hadoop FileSystem), 支持读写(Kafka / Amazon Kinesis / RabbitMQ)</p><p>Apache Kafka (Source / Sink)</p><p>Apache Cassandra (Sink)</p><p>Amazon Kinesis Streams (Source / Sink)</p><p>Elasticsearch (Sink)</p><p>Hadoop FileSystem (Sink)</p><p>RabbitMQ (Source / Sink)</p><p>Apache NiFI (Source / Sink)</p><p>Twitter Streaming API (Source)</p><p><strong>Apache Bahir 中的连接器</strong>:</p><p>Apache ActiveMQ (Source / Sink)</p><p>Apache Flume (Sink)</p><p>Redis (Sink)</p><p>Akka (Sink)</p><p>Netty (Source)</p></li></ul><p><strong>以Kafka 为例 做演示</strong></p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">final</span> StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 配置 kafka 连接参数</span></span><br><span class="line">String topic = <span class="string">"topic_name"</span>;</span><br><span class="line">String bootStrapServers = <span class="string">"localhost:9092"</span>;</span><br><span class="line">String zkConnect = <span class="string">"localhost:2181"</span>;</span><br><span class="line">String groupID = <span class="string">"group_A"</span>;</span><br><span class="line">Properties prop = <span class="keyword">new</span> Properties();</span><br><span class="line">prop.setProperty(<span class="string">"bootstrap.servers"</span>, bootStrapServers);</span><br><span class="line">prop.setProperty(<span class="string">"zookeeper.connect"</span>, zkConnect);</span><br><span class="line">prop.setProperty(<span class="string">"group.id"</span>, groupID);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 创建 kafka connector source</span></span><br><span class="line">FlinkKafkaConsumer010&lt;String&gt; consumer010 = <span class="keyword">new</span> FlinkKafkaConsumer010&lt;&gt;(topic, <span class="keyword">new</span> SimpleStringSchema(), prop);</span><br><span class="line"></span><br><span class="line"><span class="comment">// add source</span></span><br><span class="line">DataStreamSource&lt;String&gt; dataStream = env.addSource(consumer010);</span><br></pre></td></tr></table></figure><ul><li><p>自定义数据源连接器</p><p>用户也可以自己定义连接器, 通过实现 SourceFunction 定义单个线程的接入的数据连接器, 也可以通过实现ParallelSourceFunction 接口或者继承 RichParallelSourceFunction 类定义并发数据源接入器.</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
            <tag> dataSource </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>flink使用02-从WordCount开始</title>
      <link href="/2019/09/03/flink%E4%BD%BF%E7%94%A802-%E4%BB%8EWordCount%E5%BC%80%E5%A7%8B/"/>
      <url>/2019/09/03/flink%E4%BD%BF%E7%94%A802-%E4%BB%8EWordCount%E5%BC%80%E5%A7%8B/</url>
      
        <content type="html"><![CDATA[<p>相信大家在学习spark的时候接触的第一个案例肯定也是 wordCount, 本文也想通过这样一个简单的例子来讲一下一个简单的 flink 程序是什么样子的, 让大家对 flink 的代码有一个简单的了解.</p><p>一个 flink程序主要分为5个部分:</p><ul><li><strong>1. 获取执行 Environment</strong></li></ul><p>environment 提供控制 job 执行的方法(例如设置并行度/容错/checkpoint 参数) 并且与外部系统做交互. flink可以做流计算也可以做批计算, 对应的也就有不同的environment , 在使用时根据不同的使用场景选择即可.</p><ul><li><p><strong>2. 获取输入流 Source</strong></p><p>一个流式计算框架自然是少不了数据的输入, 在 streamExecutionEnvironment 的可以看到有很多种创建输入流的方式, 不过在项目中使用最多的还是使用 addSource()方法来添加不同的数据源接入</p><p><img src="/2019/09/03/flink使用02-从WordCount开始/%E6%95%B0%E6%8D%AE%E6%BA%90%E6%8E%A5%E5%85%A5%E6%96%B9%E6%B3%95.png" alt></p></li><li><p><strong>3. 执行计算 Operator</strong></p><p>在spark中,对数据的转换计算是通过 action 算子和 transformation 算子来对 RDD 中的数据来进行操作, 而在flink中, 主要是通过 Operator来对一个流做处理, 通过一个 Operator 可以将一个流转换为另外一个流, flink中内置了很多算子来实现Operator操作.</p></li><li><p><strong>4. 输入结果 Sink</strong></p><p>在完成数据计算之后,就需要有一个输出的地方, 通常来讲也是通过 addSink() 方法来添加不同的数据输出目标,也可以通过 print() 来直接查看输出或者写入到csv等外部文件.</p></li><li><p><strong>5. 启动 flink,提交 job</strong></p><p>一个 flink 代码的启动执行, 必须通过 env.executor() 方法.这行代码主要做了以下事情:</p><ol><li>生成StreamGraph </li><li>生成JobGraph. </li><li>生成一系列配置</li><li>将 JobGraph和配置交给 flink 集群去运行</li><li>以本地模式运行的话,可以看到启动过程,如启动能量度,web模块,jobManager,ResourceManager,taskManager等等</li><li>启动任务</li></ol></li></ul><h4 id="以下为简单的-WordCount-代码"><a href="#以下为简单的-WordCount-代码" class="headerlink" title="以下为简单的 WordCount 代码"></a>以下为简单的 WordCount 代码</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCount</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取 StreamEnv</span></span><br><span class="line">        <span class="keyword">final</span> StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 获取 输入流</span></span><br><span class="line">        DataStream&lt;String&gt; text = env.fromElements(WordCountData.WORDS);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 执行计算Operator</span></span><br><span class="line">        DataStream&lt;Tuple2&lt;String, Integer&gt;&gt; counts</span><br><span class="line">                = text.flatMap(<span class="keyword">new</span> SplitFunction())</span><br><span class="line">                .keyBy(<span class="number">0</span>).sum(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 输出结果</span></span><br><span class="line">        counts.print();</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 启动flink程序</span></span><br><span class="line">        env.execute(<span class="string">"WordCount Demo"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// *************************************************************************</span></span><br><span class="line">    <span class="comment">// 自定义切割Function切分一行输入</span></span><br><span class="line">    <span class="comment">// *************************************************************************</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="class"><span class="keyword">class</span> <span class="title">SplitFunction</span> <span class="keyword">implements</span> <span class="title">FlatMapFunction</span>&lt;<span class="title">String</span>, <span class="title">Tuple2</span>&lt;<span class="title">String</span>, <span class="title">Integer</span>&gt;&gt;</span>&#123;</span><br><span class="line"></span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">flatMap</span><span class="params">(String s, Collector&lt;Tuple2&lt;String, Integer&gt;&gt; collector)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">            String[] words = s.toLowerCase().split(<span class="string">" "</span>);</span><br><span class="line">            <span class="keyword">for</span> (String word : words) &#123;</span><br><span class="line">                <span class="keyword">if</span> (word.length() &gt; <span class="number">0</span>)&#123;</span><br><span class="line">                    collector.collect(<span class="keyword">new</span> Tuple2&lt;&gt;(word, <span class="number">1</span>));</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>flink使用01-本系列简介</title>
      <link href="/2019/09/03/flink%E4%BD%BF%E7%94%A801-%E6%9C%AC%E7%B3%BB%E5%88%97%E7%AE%80%E4%BB%8B/"/>
      <url>/2019/09/03/flink%E4%BD%BF%E7%94%A801-%E6%9C%AC%E7%B3%BB%E5%88%97%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<p>​    Flink 是一款能够同时支持高吞吐/低延迟/高性能的分布式处理框架.</p><p>​    本系列叫做 &lt;Flink简易使用教程&gt;,  目的是记录自己学习 flink 的过程,并且把使用flink的方方面面介绍给大家.尽量用简单的话把使用方法说清楚,在使用某个具体功能的时候能够快速的查找到该使用方法.</p><p>​    本系列的主要例子会从 flink 官方仓库的 example 出发, 通过这些代码来使用 flink 的一些基本操作.</p><p><img src="/2019/09/03/flink使用01-本系列简介/flinkExample.png" alt></p>]]></content>
      
      
      <categories>
          
          <category> flink </category>
          
      </categories>
      
      
        <tags>
            
            <tag> flink </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
